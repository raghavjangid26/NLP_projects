{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d992bcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d24d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"let's\", 'play', 'a', 'game,', 'Would', 'You', 'Rather!']\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization using the split() function\n",
    "\n",
    "my_text = \"\"\"let's play a game, Would You Rather!\"\"\"\n",
    "\n",
    "print(my_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbdd3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import(word_tokenize, sent_tokenize, TreebankWordTokenizer, wordpunct_tokenize, TweetTokenizer, MWETokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0140ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Work hard stay healthy think positive! #Nitish #Patil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631ce577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Work', 'hard', 'stay', 'healthy', 'think', 'positive', '!', '#', 'Nitish', '#', 'Patil']\n"
     ]
    }
   ],
   "source": [
    "#word tokenizer\n",
    "\n",
    "print(word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c82f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Work hard stay healthy think positive!', '#Nitish #Patil']\n"
     ]
    }
   ],
   "source": [
    "#sentence tokenizer\n",
    "\n",
    "print(sent_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d5a4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello guys.', 'Welcome to the AAFT.', 'You are studying NLP article']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello guys. Welcome to the AAFT. You are studying NLP article\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41effc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'guys',\n",
       " '.',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'AAFT',\n",
       " '.',\n",
       " 'You',\n",
       " 'are',\n",
       " 'studying',\n",
       " 'NLP',\n",
       " 'article']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello guys. Welcome to the AAFT. You are studying NLP article\"\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc4a68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'guys',\n",
       " '.',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'AAFT',\n",
       " '?',\n",
       " 'You',\n",
       " 'are',\n",
       " 'studying',\n",
       " 'NLP',\n",
       " 'article']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello guys. Welcome to the AAFT? You are studying NLP article\"\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a93635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello guys.', 'Welcome to the AAFT?', 'You are studying NLP article']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello guys. Welcome to the AAFT? You are studying NLP article\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "754441e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'guys', '.', 'Welcome', 'to', 'the', 'AAFT', '?', 'You', 'are', 'studying', 'NLP', 'article']\n"
     ]
    }
   ],
   "source": [
    "#punctuation based tokenizer: this tokenizer split the sentence into words based on whitespace and punctuation\n",
    "\n",
    "print(wordpunct_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2951e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree bank Wod tokenizer\n",
    "#this tokenizer imcorporates a variety of common rules for english word tokenization. it separates phrases-termimating punctuation (?!.,;)\n",
    "#from adjacent tokens and retains decimal number as a single token. Besides, it contains rules for enlish contraction\n",
    "# for example \"don't\" is tokenized as [\"do\", \"n't\"]. you can find all the rules for the Treebank tokenizer at this link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31582dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'do', 'you', 'do', \"n't\", 'want', 'to', 'done', 'to', 'yourself', ',', 'do', \"n't\", 'do', 'to', 'others', '...']\n"
     ]
    }
   ],
   "source": [
    "txt1 = \"what do you don't want to done to yourself,don't do to others...\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "print(tokenizer.tokenize(txt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "816fe08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'ðŸ‘‹', 'guys', '.', 'Welcome', 'ðŸ˜Š', 'to', 'the', 'AAFT', '.', 'You', 'are', 'studying', 'ðŸ’»', 'NLP', 'article']\n"
     ]
    }
   ],
   "source": [
    "tweet = \"HelloðŸ‘‹ guys. WelcomeðŸ˜Š to the AAFT. You are studyingðŸ’» NLP article\"\n",
    "tokenizer = TweetTokenizer()\n",
    "print(tokenizer.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64db41ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hope', ',', 'is', 'the', 'only', 'thing', 'stronger', 'than', 'fear', '!', 'Hunger', 'Games', '#', 'Hope']\n"
     ]
    }
   ],
   "source": [
    "txt2 = \"Hope, is the only thing stronger than fear! Hunger Games #Hope\"\n",
    "tokenizer = MWETokenizer()\n",
    "print(tokenizer.tokenize(word_tokenize(txt2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a10ea590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hope', ',', 'is', 'the', 'only', 'thing', 'stronger', 'than', 'fear', '!', 'Hunger_Games', '#', 'Hope']\n"
     ]
    }
   ],
   "source": [
    "txt2 = \"Hope, is the only thing stronger than fear! Hunger Games #Hope\"\n",
    "tokenizer = MWETokenizer()\n",
    "tokenizer.add_mwe(('Hunger', 'Games'))\n",
    "print(tokenizer.tokenize(word_tokenize(txt2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da68c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
